{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas\n",
    "import numpy as np\n",
    "from itertools import combinations, permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "# columns: category, subcategory, subcategory ID, word1, word2\n",
    "\n",
    "# creates a dictionary from given list (list of dicts = dataframe rows)\n",
    "row = lambda elements: {col:elem for col, elem in zip((\"category\", \"relation\", \"relation_ID\", \"word_1\", \"word_2\"), elements)}\n",
    "\n",
    "\n",
    "# go through all directories and files and create rows \n",
    "def read_files(verbose=False):\n",
    "    rows = []\n",
    "    data_folder = \"datasets/BATS_3.0/\"\n",
    "    \n",
    "    # 4 categories\n",
    "    for category_dir in sorted(os.listdir(data_folder)):\n",
    "        if not os.path.isdir(data_folder + category_dir): continue\n",
    "        if verbose: print(category_dir)\n",
    "        category = re.sub('_',' ',category_dir)[2:]\n",
    "        # 10 relations per category\n",
    "        for subcategory_dir in sorted(os.listdir(data_folder + category_dir)):\n",
    "            if verbose: print(subcategory_dir)\n",
    "            temp = subcategory_dir.split(' ')\n",
    "            subcategory_ID = temp[0]\n",
    "            subcategory = re.sub('\\].txt', '', re.sub('\\[','',' '.join(temp[1:])))\n",
    "            # 50 pairs per relation\n",
    "            with open(data_folder + category_dir + '/' + subcategory_dir) as f:\n",
    "                for line in f:\n",
    "                    word1, word2_list = line.strip().split('\\t')\n",
    "                    word2_list = word2_list.split('/')\n",
    "                    # break up multiple answers\n",
    "                    for word2 in word2_list:\n",
    "                        rows.append(row((category, subcategory, subcategory_ID, word1, word2)))\n",
    "    return rows\n",
    "\n",
    "def get_relations(df):\n",
    "    return df.relation.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = read_files()\n",
    "df = pandas.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>relation</th>\n",
       "      <th>relation_ID</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Derivational morphology</td>\n",
       "      <td>adj+ness_reg</td>\n",
       "      <td>D05</td>\n",
       "      <td>related</td>\n",
       "      <td>relatedness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>Derivational morphology</td>\n",
       "      <td>verb+able_reg</td>\n",
       "      <td>D07</td>\n",
       "      <td>adjust</td>\n",
       "      <td>adjustable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>Lexicographic semantics</td>\n",
       "      <td>hyponyms - misc</td>\n",
       "      <td>L03</td>\n",
       "      <td>tool</td>\n",
       "      <td>abrader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>Encyclopedic semantics</td>\n",
       "      <td>UK_city - county</td>\n",
       "      <td>E03</td>\n",
       "      <td>ely</td>\n",
       "      <td>cambridgeshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>Lexicographic semantics</td>\n",
       "      <td>hyponyms - misc</td>\n",
       "      <td>L03</td>\n",
       "      <td>cutlery</td>\n",
       "      <td>carving_fork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Encyclopedic semantics</td>\n",
       "      <td>animal - shelter</td>\n",
       "      <td>E08</td>\n",
       "      <td>beaver</td>\n",
       "      <td>pen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>Lexicographic semantics</td>\n",
       "      <td>hypernyms - animals</td>\n",
       "      <td>L01</td>\n",
       "      <td>coyote</td>\n",
       "      <td>canid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>Lexicographic semantics</td>\n",
       "      <td>hypernyms - animals</td>\n",
       "      <td>L01</td>\n",
       "      <td>viper</td>\n",
       "      <td>snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Encyclopedic semantics</td>\n",
       "      <td>country - capital</td>\n",
       "      <td>E01</td>\n",
       "      <td>tbilisi</td>\n",
       "      <td>georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>Lexicographic semantics</td>\n",
       "      <td>meronyms - part</td>\n",
       "      <td>L06</td>\n",
       "      <td>bird</td>\n",
       "      <td>uropygial_gland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>Lexicographic semantics</td>\n",
       "      <td>hyponyms - misc</td>\n",
       "      <td>L03</td>\n",
       "      <td>poem</td>\n",
       "      <td>haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Derivational morphology</td>\n",
       "      <td>re+verb_reg</td>\n",
       "      <td>D06</td>\n",
       "      <td>cognize</td>\n",
       "      <td>recognize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>Lexicographic semantics</td>\n",
       "      <td>hypernyms - misc</td>\n",
       "      <td>L02</td>\n",
       "      <td>pastry</td>\n",
       "      <td>baked_goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Derivational morphology</td>\n",
       "      <td>over+adj_reg</td>\n",
       "      <td>D04</td>\n",
       "      <td>taken</td>\n",
       "      <td>overtaken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>Encyclopedic semantics</td>\n",
       "      <td>things - color</td>\n",
       "      <td>E09</td>\n",
       "      <td>cauliflower</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category             relation relation_ID       word_1  \\\n",
       "792   Derivational morphology         adj+ness_reg         D05      related   \n",
       "858   Derivational morphology        verb+able_reg         D07       adjust   \n",
       "4965  Lexicographic semantics      hyponyms - misc         L03         tool   \n",
       "1223   Encyclopedic semantics     UK_city - county         E03          ely   \n",
       "4157  Lexicographic semantics      hyponyms - misc         L03      cutlery   \n",
       "1634   Encyclopedic semantics     animal - shelter         E08       beaver   \n",
       "2170  Lexicographic semantics  hypernyms - animals         L01       coyote   \n",
       "2732  Lexicographic semantics  hypernyms - animals         L01        viper   \n",
       "1123   Encyclopedic semantics    country - capital         E01      tbilisi   \n",
       "5542  Lexicographic semantics      meronyms - part         L06         bird   \n",
       "4722  Lexicographic semantics      hyponyms - misc         L03         poem   \n",
       "814   Derivational morphology          re+verb_reg         D06      cognize   \n",
       "3330  Lexicographic semantics     hypernyms - misc         L02       pastry   \n",
       "742   Derivational morphology         over+adj_reg         D04        taken   \n",
       "1764   Encyclopedic semantics       things - color         E09  cauliflower   \n",
       "\n",
       "               word_2  \n",
       "792       relatedness  \n",
       "858        adjustable  \n",
       "4965          abrader  \n",
       "1223   cambridgeshire  \n",
       "4157     carving_fork  \n",
       "1634              pen  \n",
       "2170            canid  \n",
       "2732            snake  \n",
       "1123          georgia  \n",
       "5542  uropygial_gland  \n",
       "4722            haiku  \n",
       "814         recognize  \n",
       "3330      baked_goods  \n",
       "742         overtaken  \n",
       "1764            white  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_questions():\n",
    "    question_list = []\n",
    "    data_folder = \"datasets/BATS_3.0/\"\n",
    "    \n",
    "    # 4 categories\n",
    "    for category_dir in sorted(os.listdir(data_folder)):\n",
    "        if not os.path.isdir(data_folder + category_dir): continue\n",
    "        # 10 relations per category\n",
    "        for subcategory_dir in sorted(os.listdir(data_folder + category_dir)):\n",
    "            # 50 pairs per relation\n",
    "            with open(data_folder + category_dir + '/' + subcategory_dir) as f:\n",
    "                pairs = []\n",
    "                for line in f:\n",
    "                    word1, word2_list = line.strip().split('\\t')\n",
    "                    # break up multiple choices\n",
    "                    #for word2 in word2_list.split('/'):\n",
    "                    pairs.append((word1, word2_list))\n",
    "                temp = [q for q in permutations(pairs, 2)]\n",
    "                for x in temp:\n",
    "                    if not x[0][0] == x[1][0]:\n",
    "                        question_list.append(x)\n",
    "                \n",
    "    return np.array(question_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = create_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98000, 2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
